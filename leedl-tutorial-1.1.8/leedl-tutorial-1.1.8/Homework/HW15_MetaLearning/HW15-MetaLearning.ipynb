{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  &#x1F4D1; **作业 15: Meta Learning**","metadata":{}},{"cell_type":"markdown","source":"# 导入包","metadata":{}},{"cell_type":"code","source":"import glob\nimport random\nimport os\nfrom collections import OrderedDict\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport torch, torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom IPython.display import display\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"DEVICE = {device}\")\n\ndef all_seed(seed=6666):\n    np.random.seed(seed)\n    random.seed(seed)\n    # CPU\n    torch.manual_seed(seed)\n    # GPU\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.cuda.manual_seed(seed)\n    # python全局\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    # cudnn\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.enabled = False\n    print(f'Set env random_seed = {seed}')\n\nall_seed(0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-30T13:22:28.521635Z","iopub.execute_input":"2023-08-30T13:22:28.522031Z","iopub.status.idle":"2023-08-30T13:22:31.931598Z","shell.execute_reply.started":"2023-08-30T13:22:28.521996Z","shell.execute_reply":"2023-08-30T13:22:31.930622Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"DEVICE = cuda\nSet env random_seed = 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 模型构建准备工作\n\n由于我们的任务是图像分类，我们需要**建立一个基于CNN的模型**。   \n然而，要实现MAML算法，**我们需要调整“nn.Module”中的一些代码。**","metadata":{}},{"cell_type":"markdown","source":"MAML伪代码\n\n\\begin{aligned}\n    &\\rule{110mm}{0.4pt}                                                                 \\\\\n    &\\text{Algorithm2  MAML for Few-Shot Supervised Learning}\\\\\n    &\\rule{110mm}{0.4pt}                                                                 \\\\\n    &\\textbf{Require: } p(\\mathcal{T}): \\text{distribution over tasks}\\\\\n    &\\textbf{Require: } \\alpha \\text{: 一系列task训练-supportSet，梯度更新学习率-在循环内更新} \\\\ \n    &\\hspace{17mm} \\beta \\text{: 一系列task评估-querySet，梯度更新学习率-在循环外更新}\\\\\n    &\\rule{110mm}{0.4pt}                                                                 \\\\\n    &\\text{ 1: 初始化参数 } \\theta \\\\\n    &\\text{ 2: }\\textbf{while }\\text{not done }\\textbf{do }\\\\\n    &\\text{ 3: }\\hspace{5mm}\\text{从任务集合中抽取任务 }\\mathcal{T}_i \\sim  p(\\mathcal{T}) \\\\\n    &\\hspace{10mm}\\text{这部分和notbook中的 Omniglot、dataloader_init、get_meta_batch 基本一致} \\\\\n    &\\text{ 4: }\\hspace{5mm}\\textbf{for all }\\mathcal{T}_i\\textbf{ do }\\\\\n    &\\text{ 5: }\\hspace{10mm}\\text{从任务中抽取k_shot个样本} \\mathcal{D}=\\{X^j, Y^j\\} \\in \\mathcal{T}_i\\\\\n    &\\text{ 6: }\\hspace{10mm}\\text{基于任务的损失函数计算损失} \\mathcal{L}_{\\mathcal{T}_i}=l(Y^j, f_{\\theta_{i}}(X^j))\\\\\n    &\\text{ 7: }\\hspace{10mm}\\text{基于损失函数计算梯度, 并更新参数} \\frac{\\partial{\\mathcal{L}_{\\mathcal{T}_i}}}{\\partial \\theta_i} = \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(f_\\theta) \\\\\n    &\\hspace{17mm} \\theta_i^{\\prime} = \\theta - \\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(f_\\theta) \\\\\n    &\\text{ 8: }\\hspace{10mm}\\text{从任务中抽取q_query个样本} \\mathcal{D}^{\\prime}=\\{X^j, Y^j\\} \\in \\mathcal{T}_i\\\\\n    &\\hspace{15mm} \\text{基于更新后的}\\theta^{\\prime}\\text{进行预测并计算损失，用于循环后更新} \\mathcal{L}^{\\prime}_{\\mathcal{T}_i}=l(Y^j, f_{\\theta^{\\prime}_{i}}(X^j))\\\\\n    &\\hspace{15mm} \\text{计算梯度}\\frac{\\partial{\\mathcal{L}^{\\prime}_{\\mathcal{T}_i}}}{\\partial \\theta^{\\prime}_i} = \\nabla_\\theta \\mathcal{L}^{\\prime}_{\\mathcal{T}_i}(f_{\\theta^{\\prime}}) \\\\\n    &\\hspace{15mm} \\text{计算最终梯度} \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(f_{\\theta^{\\prime}})  = \\frac{\\partial{\\mathcal{L}^{\\prime}_{\\mathcal{T}_i}}}{\\partial \\theta_i}=\\frac{\\partial{\\mathcal{L}^{\\prime}_{\\mathcal{T}_i}}}{\\partial \\theta^{\\prime}_i}\\frac{\\partial \\theta^{\\prime}_i}{\\partial \\theta_i} \\\\\n    &\\text{ 9: }\\hspace{5mm}\\textbf{end for}  \\\\\n    &\\text{10: }\\hspace{5mm}\\text{Update } \\theta \\leftarrow \\theta - \\beta \\sum_{\\mathcal{T}_i \\sim p(\\mathcal{T})} \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(f_{\\theta^{\\prime}})  \\\\\n    &\\text{11: }\\textbf{end while } \\\\\n    &\\bf{return} \\:  \\theta                                                     \\\\[-1.ex]\n    &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n\\end{aligned}\n\n\n在第10行, 我们希望使用初始$\\theta$(<font color=\"#0CC\">**模型初始参数**</font> )进行梯度下降（会存在二阶导， 梯度计算可以看第8行），\n\n所以在<font color=\"#0C0\">**循环内**</font>（第7行）\n- 我们构建连续梯度图`torch.autograd.grad(loss, fast_weights.values(), create_graph=True)`\n- 并用`functional_forward`进行推理，手动实现SGD进行更新参数，而不是用`forward`和`backward` \n- 当我们采用`First-order approximation`的时候，直接将连续梯度图关闭就行\n  - 即`torch.autograd.grad(loss, fast_weights.values(), create_graph=False)`\n","metadata":{}},{"cell_type":"markdown","source":"## **Step 1: 模型块定义`Model block definition`**","metadata":{}},{"cell_type":"code","source":"def ConvBlock(in_ch: int, out_ch: int):\n    return nn.Sequential(\n        nn.Conv2d(in_ch, out_ch, 3, padding=1),\n        nn.BatchNorm2d(out_ch),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n    )\n\n\n# 利用指定权重进行foward\ndef ConvBlockFunction(x, w, b, w_bn, b_bn):\n    x = F.conv2d(x, w, b, padding=1)\n    x = F.batch_norm(\n        x, running_mean=None, running_var=None, weight=w_bn, bias=b_bn, training=True\n    )\n    x = F.relu(x)\n    x = F.max_pool2d(x, kernel_size=2, stride=2)\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:22:32.141703Z","iopub.execute_input":"2023-08-30T13:22:32.142696Z","iopub.status.idle":"2023-08-30T13:22:32.150622Z","shell.execute_reply.started":"2023-08-30T13:22:32.142656Z","shell.execute_reply":"2023-08-30T13:22:32.149605Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### 模型定义","metadata":{}},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self, in_ch, k_way):\n        super(Classifier, self).__init__()\n        self.conv1 = ConvBlock(in_ch, 64)\n        self.conv2 = ConvBlock(64, 64)\n        self.conv3 = ConvBlock(64, 64)\n        self.conv4 = ConvBlock(64, 64)\n        self.logits = nn.Linear(64, k_way)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = x.view(x.shape[0], -1)\n        x = self.logits(x)\n        return x\n\n    def functional_forward(self, x, params):\n        \"\"\"\n        使用指定参数进行推理\n        params:\n            x: 输入图片 [batch, 1, 28, 28]\n            params: OrderedDict 模型参数,\n                i.e. 卷积层的 weights 和 biases 与 `batch normalization`的 weights 和 biases\n        \"\"\"\n        for block in [1, 2, 3, 4]:\n            x = ConvBlockFunction(\n                x,\n                params[f\"conv{block}.0.weight\"],\n                params[f\"conv{block}.0.bias\"],\n                params.get(f\"conv{block}.1.weight\"),\n                params.get(f\"conv{block}.1.bias\"),\n            )\n        x = x.view(x.shape[0], -1)\n        x = F.linear(x, params[\"logits.weight\"], params[\"logits.bias\"])\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:22:33.704577Z","iopub.execute_input":"2023-08-30T13:22:33.705652Z","iopub.status.idle":"2023-08-30T13:22:33.716330Z","shell.execute_reply.started":"2023-08-30T13:22:33.705608Z","shell.execute_reply":"2023-08-30T13:22:33.715190Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## **Step 2: 创建标签**\n\n`create_label` 用于创建标签\n\n对于`N-way K-shot few-shot`分类问题中,\n- `n_way`  表示n个类别, \n- `k_shot` K表示每个类的样本数.  \n","metadata":{}},{"cell_type":"code","source":"def create_label(n_way, k_shot):\n    return torch.arange(n_way).repeat_interleave(k_shot).long()\n\n\ncreate_label(5, 2)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:22:34.592778Z","iopub.execute_input":"2023-08-30T13:22:34.593488Z","iopub.status.idle":"2023-08-30T13:22:34.675241Z","shell.execute_reply.started":"2023-08-30T13:22:34.593455Z","shell.execute_reply":"2023-08-30T13:22:34.674295Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4])"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Step 3: 计算`Accuracy`**","metadata":{}},{"cell_type":"code","source":"def calculate_accuracy(logits, labels):\n    \"\"\"utility function for accuracy calculation\"\"\"\n    acc = np.asarray(\n        [(torch.argmax(logits, -1).cpu().numpy() == labels.cpu().numpy())]\n    ).mean()\n    return acc","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:22:35.810611Z","iopub.execute_input":"2023-08-30T13:22:35.811325Z","iopub.status.idle":"2023-08-30T13:22:35.816837Z","shell.execute_reply.started":"2023-08-30T13:22:35.811289Z","shell.execute_reply":"2023-08-30T13:22:35.815654Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## **Step 4: 定义 Dataset**\n\n`dataset` 返回随机抽取的一个类型的 (`k_shot + q_query`)张图片\n\n返回张量的大小为： `[k_shot + q_query, 1, 28, 28]`.  \n","metadata":{}},{"cell_type":"code","source":"data_dir = '../input/ml2022spring-hw15/omniglot'\ntrain_data_path = f\"{data_dir}/Omniglot/images_background/\"\nfile_list = [\n            f for f in glob.glob(train_data_path + \"**/character*\", recursive=True)\n        ]\nlen(file_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:22:37.167038Z","iopub.execute_input":"2023-08-30T13:22:37.167397Z","iopub.status.idle":"2023-08-30T13:22:56.258477Z","shell.execute_reply.started":"2023-08-30T13:22:37.167367Z","shell.execute_reply":"2023-08-30T13:22:56.257504Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"964"},"metadata":{}}]},{"cell_type":"code","source":"file_list[:10]","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:22:56.260264Z","iopub.execute_input":"2023-08-30T13:22:56.260781Z","iopub.status.idle":"2023-08-30T13:22:56.267194Z","shell.execute_reply.started":"2023-08-30T13:22:56.260744Z","shell.execute_reply":"2023-08-30T13:22:56.266254Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character15',\n '../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character11',\n '../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character35',\n '../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character21',\n '../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character38',\n '../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character24',\n '../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character28',\n '../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character12',\n '../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character04',\n '../input/ml2022spring-hw15/omniglot/Omniglot/images_background/Armenian.0/character20']"},"metadata":{}}]},{"cell_type":"code","source":"class Omniglot(Dataset):\n    def __init__(self, data_dir, k_shot, q_query, task_num=None):\n        # 路径tree如下\n        #         ../input/ml2022spring-hw15/omniglot/Omniglot/images_background\n        #         ├── Alphabet_of_the_Magi.0\n        #         │   ├── character01\n        #         │   │   ├── 0709_01.png\n        #         │   │   ├── 0709_02.png\n        #         │   │   ├── ...\n        #         │   ├── character02\n        #         │   │   ├── 0710_01.png\n        #         │   │   ├── 0710_02.png\n        #         │   │   ├── ...\n        #         │   ├── character03\n        #         │   │   ├── 0711_01.png\n        #         │   │   ├── 0711_02.png\n        #         │   │   ├── ...\n        # 获取所有classifier :  dir/[type]/character[x]\n        self.file_list = [\n            f for f in glob.glob(data_dir + \"**/character*\", recursive=True)\n        ]\n        # 限制 task_num 数量的classifier\n        if task_num is not None:\n            self.file_list = self.file_list[: min(len(self.file_list), task_num)]\n        self.transform = transforms.Compose([transforms.ToTensor()])\n        # 输出\n        self.n = k_shot + q_query\n\n    def __getitem__(self, idx):\n        # 取其中的一个 classifier\n        img_path = self.file_list[idx]\n        img_list = [f for f in glob.glob(img_path + \"**/*.png\", recursive=True)]\n        img_list.sort()\n        imgs = [self.transform(Image.open(img_file)) for img_file in img_list]\n        \n        # 每个 classifier 随机抽取 `k_shot + q_query` 张img\n        sample = np.arange(20)\n        np.random.shuffle(sample)\n        random_idx_list = sample[:self.n]\n        imgs = torch.stack(imgs)[random_idx_list]\n        return imgs\n\n    def __len__(self):\n        return len(self.file_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:22:56.268922Z","iopub.execute_input":"2023-08-30T13:22:56.269614Z","iopub.status.idle":"2023-08-30T13:22:56.281037Z","shell.execute_reply.started":"2023-08-30T13:22:56.269577Z","shell.execute_reply":"2023-08-30T13:22:56.280077Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## &#x2728; **Step 5: 算法实现`Learning Algorithms`**\n\n### 迁移学习`Transfer learning`\n\n`BaseSolver`首先会从训练集中抽取5个任务， 然后在5个任务上依次进行正常的分类器训练。  \n在推理阶段，模型在`support`样本上进行`inner_train_step`微调， 然后在`query`数据上进行推理  \n为了与元学习(`meta learning`)求解器保持一致，基础求解器具有与元学习解算器完全相同的输入和输出格式。","metadata":{}},{"cell_type":"code","source":"def BaseSolver(\n    model,\n    optimizer,\n    x,\n    n_way,\n    k_shot,\n    q_query,\n    loss_fn,\n    inner_train_step=1,\n    inner_lr=0.4,\n    train=True,\n    return_labels=False,\n):\n    criterion, task_loss, task_acc = loss_fn, [], []\n    labels = []\n\n    for meta_batch in x:\n        # 获取数据 \n        support_set = meta_batch[: n_way * k_shot]\n        query_set = meta_batch[n_way * k_shot :]\n\n        if train:\n            \"\"\" training loop \"\"\"\n            # 使用support set计算损失\n            labels = create_label(n_way, k_shot).to(device)\n            logits = model.forward(support_set)\n            loss = criterion(logits, labels)\n\n            task_loss.append(loss)\n            task_acc.append(calculate_accuracy(logits, labels))\n        else:\n            \"\"\" validation / testing loop \"\"\"\n            # 用 support set 图片进行 `inner_train_step` 微调\n            fast_weights = OrderedDict(model.named_parameters())\n            for inner_step in range(inner_train_step):\n                train_label = create_label(n_way, k_shot).to(device)\n                logits = model.functional_forward(support_set, fast_weights)\n                loss = criterion(logits, train_label)\n\n                grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n                # Perform SGD\n                fast_weights = OrderedDict(\n                    (name, param - inner_lr * grad)\n                    for ((name, param), grad) in zip(fast_weights.items(), grads)\n                )\n\n            if not return_labels:\n                \"\"\" validation \"\"\"\n                val_label = create_label(n_way, q_query).to(device)\n\n                logits = model.functional_forward(query_set, fast_weights)\n                loss = criterion(logits, val_label)\n                task_loss.append(loss)\n                task_acc.append(calculate_accuracy(logits, val_label))\n            else:\n                \"\"\" testing \"\"\"\n                logits = model.functional_forward(query_set, fast_weights)\n                labels.extend(torch.argmax(logits, -1).cpu().numpy())\n\n    if return_labels:\n        return labels\n\n    batch_loss = torch.stack(task_loss).mean()\n    task_acc = np.mean(task_acc)\n\n    if train:\n        # 更新model\n        model.train()\n        optimizer.zero_grad()\n        batch_loss.backward()\n        optimizer.step()\n\n    return batch_loss, task_acc","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:22:56.283323Z","iopub.execute_input":"2023-08-30T13:22:56.283752Z","iopub.status.idle":"2023-08-30T13:22:56.299946Z","shell.execute_reply.started":"2023-08-30T13:22:56.283720Z","shell.execute_reply":"2023-08-30T13:22:56.299065Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### &#x2728; Meta Learning\n\n这里是Meta Learning algorithm的主要实现  \n<font color=darkred><b>TODO: </font></b>\n- <font color=darkred>实现`First Order MAML`, </font>可以参考[p.25 of the slides](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pdf#page=25&view=FitW).\n- <font color=darkred>实现一般的`original MAML`, </font>可以参考[the slides of meta learning (p.13 ~ p.18)](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pdf#page=13&view=FitW).\n\n\n","metadata":{}},{"cell_type":"code","source":"def MetaSolver(\n    model,\n    optimizer,\n    x,\n    n_way,\n    k_shot,\n    q_query,\n    loss_fn,\n    inner_train_step=1,\n    inner_lr=0.4,\n    train=True,\n    return_labels=False,\n    FO=False\n):\n    criterion, task_loss, task_acc = loss_fn, [], []\n    labels = []\n\n    for meta_batch in x:\n        # 获取数据\n        support_set = meta_batch[: n_way * k_shot]\n        query_set = meta_batch[n_way * k_shot :]\n        # 没有training loop \n        # 复制原始参数\n        fast_weights = OrderedDict(model.named_parameters())\n        ### ---------- INNER TRAIN LOOP ---------- ###\n        # support_set 进行1step训练： 关注梯度——一阶导\n        for inner_step in range(inner_train_step):\n            train_label = create_label(n_way, k_shot).to(device)\n            logits = model.functional_forward(support_set, fast_weights)\n            loss = criterion(logits, train_label)\n            \"\"\" Inner Loop Update \"\"\"\n            # TODO: 这里实现MAML\n            grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=not FO) # 便于进行二阶导\n            fast_weights = OrderedDict(\n                (name, param - inner_lr * (grad.detach().data if FO else grad) )\n                for ((name, param), grad) in zip(fast_weights.items(), grads)\n            )\n\n        ### ---------- INNER VALID LOOP ---------- ###\n        if not return_labels:\n            \"\"\" training / validation \"\"\"\n            # query_set 进行测试： 关注loss——二阶导\n            val_label = create_label(n_way, q_query).to(device)\n            logits = model.functional_forward(query_set, fast_weights)\n            loss = criterion(logits, val_label)\n            task_loss.append(loss)\n            task_acc.append(calculate_accuracy(logits, val_label))\n        else:\n            \"\"\" testing \"\"\"\n            logits = model.functional_forward(query_set, fast_weights)\n            labels.extend(torch.argmax(logits, -1).cpu().numpy())\n\n    if return_labels:\n        return labels\n\n    model.train()\n    optimizer.zero_grad()\n    meta_batch_loss = torch.stack(task_loss).mean()\n    task_acc = np.mean(task_acc)\n    if train:\n        \"\"\" Outer Loop Update \"\"\"\n        # TODO: 二阶梯度方向传播\n        meta_batch_loss.backward()\n        optimizer.step()\n\n    return meta_batch_loss, task_acc","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:29:12.051945Z","iopub.execute_input":"2023-08-30T13:29:12.052315Z","iopub.status.idle":"2023-08-30T13:29:12.066749Z","shell.execute_reply.started":"2023-08-30T13:29:12.052285Z","shell.execute_reply":"2023-08-30T13:29:12.065689Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## **Step 6: 初始化**\n\n模型及数据初始化。","metadata":{}},{"cell_type":"code","source":"n_way = 5\nk_shot = 1\nq_query = 1\ntrain_inner_train_step = 1\nval_inner_train_step = 3\ninner_lr = 0.4\nmeta_lr = 0.001\nmeta_batch_size = 32\nmax_epoch = 30\neval_batches = 20\ndata_dir = '../input/ml2022spring-hw15/omniglot'\ntrain_data_path = f\"{data_dir}/Omniglot/images_background/\"","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:29:13.164807Z","iopub.execute_input":"2023-08-30T13:29:13.165545Z","iopub.status.idle":"2023-08-30T13:29:13.171645Z","shell.execute_reply.started":"2023-08-30T13:29:13.165510Z","shell.execute_reply":"2023-08-30T13:29:13.170484Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Dataloader初始化","metadata":{}},{"cell_type":"code","source":"def dataloader_init(datasets, shuffle=True, num_workers=2):\n    train_set, val_set = datasets\n    # 这里batch_size设置成n_way\n    # 返回 [n_way, k_shot + q_query, 1, 28, 28]\n    train_loader = DataLoader(\n        train_set,\n        batch_size=n_way,\n        num_workers=num_workers,\n        shuffle=shuffle,\n        drop_last=True,\n    )\n    val_loader = DataLoader(\n        val_set, batch_size=n_way, num_workers=num_workers, shuffle=shuffle, drop_last=True\n    )\n\n    train_iter = iter(train_loader)\n    val_iter = iter(val_loader)\n    return (train_loader, val_loader), (train_iter, val_iter)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:29:31.601439Z","iopub.execute_input":"2023-08-30T13:29:31.601798Z","iopub.status.idle":"2023-08-30T13:29:31.610842Z","shell.execute_reply.started":"2023-08-30T13:29:31.601768Z","shell.execute_reply":"2023-08-30T13:29:31.609830Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Model & optimizer 初始化","metadata":{}},{"cell_type":"code","source":"def model_init():\n    meta_model = Classifier(1, n_way).to(device)\n    optimizer = torch.optim.Adam(meta_model.parameters(), lr=meta_lr)\n    loss_fn = nn.CrossEntropyLoss().to(device)\n    return meta_model, optimizer, loss_fn","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:34:15.641118Z","iopub.execute_input":"2023-08-30T13:34:15.641964Z","iopub.status.idle":"2023-08-30T13:34:15.647883Z","shell.execute_reply.started":"2023-08-30T13:34:15.641917Z","shell.execute_reply":"2023-08-30T13:34:15.646748Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### 获取`meta-batch`方法\n\n主要的作用是将 `[n_way, k_shot+q_query, 1, 28, 28]` 转变成\n`[n_way*k_shot + n_way*q_query, 1, 28, 28]` 便于在Solver中拆分成 `support_set` 和 `query_set`","metadata":{}},{"cell_type":"code","source":"def get_meta_batch(meta_batch_size, k_shot, q_query, data_loader, iterator):\n    \"\"\"\n    主要的作用是将 [n_way, k_shot+q_query, 1, 28, 28] 转变成\n    [n_way*k_shot + n_way*q_query, 1, 28, 28] 便于在Solver中拆分成 support_set 和 query_set\n    \"\"\"\n    data = []\n    for _ in range(meta_batch_size):\n        try:\n            # 一个 \"task_data\" 张量代表 一个task的data: 大小为 [n_way, k_shot+q_query, 1, 28, 28]\n            task_data = next(iterator)\n        except StopIteration:\n            iterator = iter(data_loader)\n            task_data = next(iterator) \n        train_data = task_data[:, :k_shot].reshape(-1, 1, 28, 28)\n        val_data = task_data[:, k_shot:].reshape(-1, 1, 28, 28)\n        task_data = torch.cat((train_data, val_data), 0)\n        data.append(task_data)\n    return torch.stack(data).to(device), iterator","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:34:19.101480Z","iopub.execute_input":"2023-08-30T13:34:19.101840Z","iopub.status.idle":"2023-08-30T13:34:19.109324Z","shell.execute_reply.started":"2023-08-30T13:34:19.101810Z","shell.execute_reply":"2023-08-30T13:34:19.108396Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# &#x2728; **训练与测试**","metadata":{}},{"cell_type":"markdown","source":"## 开始训练\n- `solver = 'base'`: 迁移学习(` transfer learning algorithm.`)\n- `solver = 'meta'`: 元学习(`meta learning algorithm`)\n","metadata":{}},{"cell_type":"code","source":"from functools import partial\nmeta_lr_org = meta_lr = 0.001\nsolver = 'meta' # base, meta\nFO = False\nmeta_model, optimizer, loss_fn = model_init()\n\n# 基于solver初始化训练数据\nif solver == 'base':\n    f_max_epoch = 5 # the base solver 只用 5 epochs\n    meta_lr = meta_lr_org\n    print(f'use transferLearning & f_max_epoch={f_max_epoch} & meta_lr={meta_lr}')\n    Solver = BaseSolver\n    train_set, val_set = torch.utils.data.random_split(\n        Omniglot(train_data_path, k_shot, q_query, task_num=10), [5, 5]\n    )\n    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set), shuffle=False)\n\nelif solver == 'meta':\n    f_max_epoch = max_epoch\n    meta_lr = meta_lr_org\n    if FO:\n        f_max_epoch = 40\n        meta_lr = 0.0014\n        print(f'use FO-MAML & f_max_epoch={f_max_epoch} & meta_lr={meta_lr}')\n    else:\n        print(f'use MAML & f_max_epoch={f_max_epoch} & meta_lr={meta_lr}')\n    \n    Solver = partial(MetaSolver, FO=FO)\n    dataset = Omniglot(train_data_path, k_shot, q_query)\n    train_split = int(0.8 * len(dataset))\n    val_split = len(dataset) - train_split\n    train_set, val_set = torch.utils.data.random_split(\n        dataset, [train_split, val_split]\n    )\n    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set))\nelse:\n    raise NotImplementedError\n\n\ntrain_bar = tqdm(range(f_max_epoch))\nfor epoch in train_bar:\n    train_bar.set_description(f\"[ Epoch {epoch+1:02d}/{f_max_epoch:02d} ]\")\n    train_meta_loss = []\n    train_acc = []\n    # The \"step\" here is a meta-gradinet update step\n    for step in tqdm(range(max(1, len(train_loader) // meta_batch_size))):\n        x, train_iter = get_meta_batch(\n            meta_batch_size, k_shot, q_query, train_loader, train_iter\n        )\n        meta_loss, acc = Solver(\n            meta_model,\n            optimizer,\n            x,\n            n_way,\n            k_shot,\n            q_query,\n            loss_fn, \n            inner_train_step=train_inner_train_step\n        )\n        train_meta_loss.append(meta_loss.item())\n        train_acc.append(acc)\n\n    print(\"--\"*25, f'{epoch+1:02d}', \"--\"*25)\n    print(\"  Loss    : \", \"%.3f\" % (np.mean(train_meta_loss)), end=\"\\t\")\n    print(\"  Accuracy: \", \"%.3f %%\" % (np.mean(train_acc) * 100))\n\n    # 每个epoch训练完后查看验证集的表现(validation accuracy)  \n    # 同样也可以在验证集验证的后实现`Early stopping` (可以参考 HW01 中的实现)\n    val_acc = []\n    val_loss = []\n    for eval_step in range(max(1, len(val_loader) // (eval_batches))):\n        x, val_iter = get_meta_batch(\n            eval_batches, k_shot, q_query, val_loader, val_iter\n        )\n        # test的时候进行 3次inner steps 更新参数\n        val_loss_i, acc = Solver(\n            meta_model,\n            optimizer,\n            x,\n            n_way,\n            k_shot,\n            q_query,\n            loss_fn,\n            inner_train_step=val_inner_train_step,\n            train=False,\n        )\n        val_acc.append(acc)\n        val_loss.append(val_loss_i.item())\n\n    train_bar.set_postfix({\n        \"trainLoss\": \"%.3f\" % (np.mean(train_meta_loss)),\n        \"trainAccuracy\": \"%.3f %%\" % (np.mean(train_acc) * 100),\n        \"valLoss\": \"%.3f\" % (np.mean(val_loss)),\n        \"valAccuracy\": \"%.3f %%\" % (np.mean(val_acc) * 100)\n    })\n    print(\"**\"*25)\n    print(\"  Validation accuracy: \", \"%.3f %%\" % (np.mean(val_acc) * 100))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:34:21.424308Z","iopub.execute_input":"2023-08-30T13:34:21.425144Z","iopub.status.idle":"2023-08-30T13:40:02.130311Z","shell.execute_reply.started":"2023-08-30T13:34:21.425102Z","shell.execute_reply":"2023-08-30T13:40:02.128012Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"use MAML & f_max_epoch=30 & meta_lr=0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56bb1a89dac449aeb1e30bf6a3fd4b7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd3dadd69304c8e97d670fe48d5d3a3"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 01 --------------------------------------------------\n  Loss    :  2.480\t  Accuracy:  26.719 %\n**************************************************\n  Validation accuracy:  32.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e32302b821ff45babd7125a7dfa7a22e"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 02 --------------------------------------------------\n  Loss    :  1.368\t  Accuracy:  42.500 %\n**************************************************\n  Validation accuracy:  40.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"887a111a571248bd8b945dec5bf46656"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 03 --------------------------------------------------\n  Loss    :  1.262\t  Accuracy:  47.344 %\n**************************************************\n  Validation accuracy:  50.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eafa0c02d3cd4eb9b917a4fae9cf04ce"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 04 --------------------------------------------------\n  Loss    :  1.207\t  Accuracy:  54.219 %\n**************************************************\n  Validation accuracy:  39.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"148010a031904531a87652632eaacd0a"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 05 --------------------------------------------------\n  Loss    :  1.180\t  Accuracy:  56.250 %\n**************************************************\n  Validation accuracy:  45.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ed073c087bc4b0aafe9cabaf240f6ec"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 06 --------------------------------------------------\n  Loss    :  1.157\t  Accuracy:  57.500 %\n**************************************************\n  Validation accuracy:  39.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f475fcd339bf4010ad963e8517b9bb51"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 07 --------------------------------------------------\n  Loss    :  1.110\t  Accuracy:  58.594 %\n**************************************************\n  Validation accuracy:  44.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c86572700d44483f85375a9ae9806d3f"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 08 --------------------------------------------------\n  Loss    :  1.119\t  Accuracy:  59.375 %\n**************************************************\n  Validation accuracy:  51.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66cb8c47e34e49b68bcfb62a56b79d63"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 09 --------------------------------------------------\n  Loss    :  1.057\t  Accuracy:  60.625 %\n**************************************************\n  Validation accuracy:  43.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"491dbc9f9bcf46df9d6f13fd4098c0f5"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 10 --------------------------------------------------\n  Loss    :  1.035\t  Accuracy:  60.938 %\n**************************************************\n  Validation accuracy:  46.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"565ae2c2b241490095365ee6ae300089"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 11 --------------------------------------------------\n  Loss    :  1.009\t  Accuracy:  64.062 %\n**************************************************\n  Validation accuracy:  52.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2967baf5d8c249ce8da1df068bada1fb"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 12 --------------------------------------------------\n  Loss    :  0.996\t  Accuracy:  60.781 %\n**************************************************\n  Validation accuracy:  51.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb6efacacef94a958bb3c4b118ecc142"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 13 --------------------------------------------------\n  Loss    :  0.984\t  Accuracy:  61.094 %\n**************************************************\n  Validation accuracy:  47.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c26d411d56fc4eb38f767420626220f3"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 14 --------------------------------------------------\n  Loss    :  0.930\t  Accuracy:  64.688 %\n**************************************************\n  Validation accuracy:  56.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb3c5a5bfff3459d80fd4ba8c02e8692"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 15 --------------------------------------------------\n  Loss    :  0.889\t  Accuracy:  66.250 %\n**************************************************\n  Validation accuracy:  53.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f75fb54978cc4fae8ec71ec01a93f2b3"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 16 --------------------------------------------------\n  Loss    :  0.865\t  Accuracy:  69.062 %\n**************************************************\n  Validation accuracy:  54.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2b82ddc19ba47619717c7eebca19c43"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 17 --------------------------------------------------\n  Loss    :  0.831\t  Accuracy:  70.312 %\n**************************************************\n  Validation accuracy:  55.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80076428b85c404c980bcbe24c846fea"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 18 --------------------------------------------------\n  Loss    :  0.785\t  Accuracy:  74.531 %\n**************************************************\n  Validation accuracy:  59.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bda1e789910b4eec8d200a21869fcb23"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 19 --------------------------------------------------\n  Loss    :  0.799\t  Accuracy:  71.562 %\n**************************************************\n  Validation accuracy:  58.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa94cc02d5764df4a7aa730a1a3626f0"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 20 --------------------------------------------------\n  Loss    :  0.772\t  Accuracy:  70.312 %\n**************************************************\n  Validation accuracy:  57.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea7dd200ee0042299949de72dde7d8c0"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 21 --------------------------------------------------\n  Loss    :  0.770\t  Accuracy:  74.531 %\n**************************************************\n  Validation accuracy:  78.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c1c39be1814407b825d08f28b3754b4"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 22 --------------------------------------------------\n  Loss    :  0.705\t  Accuracy:  77.188 %\n**************************************************\n  Validation accuracy:  66.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86ce2b1f03694e9ab6425babdd622af4"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 23 --------------------------------------------------\n  Loss    :  0.670\t  Accuracy:  77.969 %\n**************************************************\n  Validation accuracy:  71.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca9544b9eaf447dc83cf3710a656a962"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 24 --------------------------------------------------\n  Loss    :  0.666\t  Accuracy:  76.094 %\n**************************************************\n  Validation accuracy:  66.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15ef77b0b15748f8b1b35a92e5019e78"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 25 --------------------------------------------------\n  Loss    :  0.604\t  Accuracy:  80.781 %\n**************************************************\n  Validation accuracy:  85.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aae947792ec8427ebd64572d638ea983"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 26 --------------------------------------------------\n  Loss    :  0.550\t  Accuracy:  83.594 %\n**************************************************\n  Validation accuracy:  71.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b6861a8d1734aacb11be01e51851d0c"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 27 --------------------------------------------------\n  Loss    :  0.565\t  Accuracy:  80.000 %\n**************************************************\n  Validation accuracy:  83.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"111895e4190846b7a55bf288dd331b38"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 28 --------------------------------------------------\n  Loss    :  0.531\t  Accuracy:  82.344 %\n**************************************************\n  Validation accuracy:  77.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"390fc14bf95645cbb1c3ff0d5e8647d2"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 29 --------------------------------------------------\n  Loss    :  0.507\t  Accuracy:  83.281 %\n**************************************************\n  Validation accuracy:  76.000 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb92e7a533034da3b68249cc3b277147"}},"metadata":{}},{"name":"stdout","text":"-------------------------------------------------- 30 --------------------------------------------------\n  Loss    :  0.481\t  Accuracy:  84.844 %\n**************************************************\n  Validation accuracy:  78.000 %\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 测试和结果输出\n\n由于测试数据是由TA提前采样的，因此不应更改“OmnigloTest”数据集中的代码，否则在Kaggle排行榜上的分数可能不正确。  \n\n但是，可以随意更改变量`inner_train_step`来设置`query`集图像上的训练步骤。","metadata":{}},{"cell_type":"code","source":"import os\n\nclass OmniglotTest(Dataset):\n    def __init__(self, test_dir):\n        self.test_dir = test_dir\n        self.n = 5\n\n        self.transform = transforms.Compose([transforms.ToTensor()])\n\n    def __getitem__(self, idx):\n        support_files = [\n            os.path.join(self.test_dir, \"support\", f\"{idx:>04}\", f\"image_{i}.png\")\n            for i in range(self.n)\n        ]\n        query_files = [\n            os.path.join(self.test_dir, \"query\", f\"{idx:>04}\", f\"image_{i}.png\")\n            for i in range(self.n)\n        ]\n\n        support_imgs = torch.stack(\n            [self.transform(Image.open(e)) for e in support_files]\n        )\n        query_imgs = torch.stack([self.transform(Image.open(e)) for e in query_files])\n\n        return support_imgs, query_imgs\n\n    def __len__(self):\n        return len(os.listdir(os.path.join(self.test_dir, \"support\")))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:40:02.135481Z","iopub.execute_input":"2023-08-30T13:40:02.137047Z","iopub.status.idle":"2023-08-30T13:40:02.152116Z","shell.execute_reply.started":"2023-08-30T13:40:02.137005Z","shell.execute_reply":"2023-08-30T13:40:02.151073Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test_inner_train_step = 10 # 可以更改这里\n\ntest_batches = 20\ntest_data_path = '../input/ml2022spring-hw15/omniglot-test/Omniglot-test'\ntest_dataset = OmniglotTest(test_data_path)\ntest_loader = DataLoader(test_dataset, batch_size=test_batches, shuffle=False)\n\noutput = []\nfor _, batch in enumerate(tqdm(test_loader)):\n    support_set, query_set = batch\n    x = torch.cat([support_set, query_set], dim=1)\n    x = x.to(device)\n\n    labels = Solver(\n        meta_model,\n        optimizer,\n        x,\n        n_way,\n        k_shot,\n        q_query,\n        loss_fn,\n        inner_train_step=test_inner_train_step,\n        train=False,\n        return_labels=True,\n    )\n\n    output.extend(labels)\n\n# 写入 csv\nwith open(\"output.csv\", \"w\") as f:\n    f.write(f\"id,class\\n\")\n    for i, label in enumerate(output):\n        f.write(f\"{i},{label}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-08-30T13:40:02.153889Z","iopub.execute_input":"2023-08-30T13:40:02.154335Z","iopub.status.idle":"2023-08-30T13:41:10.690755Z","shell.execute_reply.started":"2023-08-30T13:40:02.154301Z","shell.execute_reply":"2023-08-30T13:41:10.689922Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ebf823aada44cc3a2c1cd7ff843261e"}},"metadata":{}}]},{"cell_type":"markdown","source":"# **参考**\n1. Chelsea Finn, Pieter Abbeel, & Sergey Levine. (2017). [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.](https://arxiv.org/abs/1909.09157)\n1. Aniruddh Raghu, Maithra Raghu, Samy Bengio, & Oriol Vinyals. (2020). [Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML.](https://arxiv.org/abs/1909.09157)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}